# 자동 회계 처리 시스템

## 1. 핵심 로직 구현 코드 (GitHub Repository)

### 기능 1: 자동 회계 처리 API (POST /api/v1/accounting/process)

bank_transactions.csv 파일과 rules.json 파일을 입력받아, 규칙에 따라 각 거래 내역을 해당하는 회사와 계정과목으로 자동 분류하여 DB에 저장하는 기능을 구현합니다.

### 기능 2: 사업체별 분류 결과 조회 API (GET /api/v1/accounting/records?companyId=...)

companyId (e.g., com_1)를 파라미터로 받아, 해당 사업체에 귀속된 거래 내역과 분류된 계정과목 정보(category_id, category_name)를 함께 반환합니다.
어떤 규칙과도 일치하지 않는 거래 내역은 특정 회사에 귀속시키지 않거나, '미분류' 항목으로 처리해야 합니다.

## 2. 설계 및 보안 아키텍처 기술서

### A. [시스템 아키텍처 👉](docs/Architecture.md) / [DB 스키마 👉](docs/DBSchema.md)

**기술 스택**: 선택하신 언어, 프레임워크, DB와 그 이유를 설명해 주세요.

**DB 스키마**: 여러 사업체를 지원하고, 거래 내역과 분류 결과를 저장할 수 있는 유연한 DB 구조를 설계해 주세요. (SQL CREATE TABLE 구문 또는 ERD)

### B. [핵심 자동 분류 로직 👉](docs/CategorizingLogic.md)

rules.json을 기반으로 거래 내역을 자동 분류하는 로직의 동작 방식을 설명해 주세요. 만약 규칙이 더 복잡해진다면(e.g., '금액 구간' 조건 추가, '제외 키워드' 설정), 현재 로직을 어떻게 개선하고
확장할 수 있을지 아이디어를 제시해 주세요.

### C. [보안 강화 방안 👉](docs/SecurityEnhancement.md)

실제 서비스에서는 은행 거래 내역, 공인인증서 등 매우 민감한 정보를 다루게 됩니다.
사용자의 공인인증서(파일, 비밀번호)를 서버에 저장하고 안전하게 사용해야 한다면,
어떤 방식으로 시스템을 구축하시겠습니까? (e.g., 저장 방식, 암호화, 키 관리, 접근 제어 등)

### D. [문제상황 해결책 제시 👉](docs/Scenario.md)

**시나리오**: 한 고객사의 거래 데이터가 다른 고객사 대시보드에 노출되었다는 신고가 들어왔습니다.
즉시 대응 조치, 원인 분석 방법, 재발 방지 대책 측면에서 해결책을 제시해주세요.

### 3. [실행 및 테스트 가이드 👉](docs/StartAndTest.md)

프로젝트를 실행하는 방법과 API를 테스트하는 방법을 명확하게 안내해 주세요. (e.g., Docker Compose, curl 명령어 예시 등)

### 4. AI(LLM 등)를 활용해서 위 과제를 진행한 경우, 아래에 해당사항이 있다면 작성해주세요.

AI는 Claude, Gemini를 사용해 구현 및 과제를 수행했습니다.

어떻게 보면 익숙하지 않은 언어와 프레임워크다 보니 문법적인 부분과 프레임워크 인터페이스, ORM 부분에서 LLM의 도움을
받았습니다.

### AI가 제안한 것과 다르게 결정한 부분이 있다면 어떤 부분인지(AI의 결과물과 VS. 내가 바꾼 결과물), 왜 그렇게 결정했는지(바꾸셨는지) 알려주세요.

<br/>

#### 프로그래밍 패러다임

FastAPI 를 AI에게 구현을 맡겼을 때는 라우터에 모든 비즈니스 로직들이 구현되어 있는 상태였습니다. 또한, 함수만으로 프로젝트가 구성되었으며 데이터베이스 연결 또한 계층적 분리가 되어있지 않은 상태였습니다.
개인적으로 저는 객체지향적인 프로그래밍을 선호합니다. 그렇기에 좀 더 구조적이고 객체지향적인 설계를 원했습니다. 객체지향적인 설계는 코드의 실행 흐름을 예측하기 쉽고
객체로 분리된 책임으로 인해 코드를 이해하기 쉽기 때문입니다.

그래서 저는 먼저 라우터(컨트롤러)를 제외하고 비즈니스 로직에 필요한 요소들을 클래스화 했으며 클린 아키텍처를 적용해 계층형 구조로 설계를 변경했습니다.
계층별로 분리하고 격리함으로써 계층간의 의존성을 낮추고 확장과 변경에 용이한 구조를 원했기 때문입니다.

<br/>

#### 시스템 아키텍처

AI의 답변은 하나의 프로세스(app)에서 모든 로직들이 처리가 되는 방식이었으나 분류 작업이 많은 리소스를 사용할 것으로 예상했기에 구조적인 개선이
있어야겠다고 생각했습니다. 예를 들어, csv 파일의 크기가 GB를 넘어가게 되면 분류 작업이 오랫동안 처리되면 API 요청에 장애가 생길 가능성이 높다고 판단했기 떄문입니다.

그래서 저는 API 요청을 처리하는 서버와 분류 작업을 하는 서버를 분리했고 서버간의 결합도를 낮추고 작업 신뢰도를 높이기 위해서 메시지 브로커를 사용해 작업을 전달하는
방식을 선택했습니다. 이런 구조는 각 서비스가 완전히 독립적으로 동작할 수 있도록 해 장애 전파 및 대응이 쉬워진다는 장점이 있기 때문입니다.


